{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Validation Set\n",
    "\n",
    "This notebook explores a subset of the GTSRB (namely the speed signs) to show how the selection of the validation set can affect our expectations when using the net in unseen data.\n",
    "\n",
    "It covers tensorflow dataset API to load local data:\n",
    "\n",
    "- how to load local data\n",
    "- prepare the dataset for training\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "https://benchmark.ini.rub.de/gtsrb_news.html\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "https://www.youtube.com/watch?v=yH1cF7GnoIo    \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/tensorflow-tutorial    \n",
    "\n",
    "https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/\n",
    "\n",
    "https://surfertas.github.io/tensorflow/dl/2018/01/24/tf-data-augmentation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions for display purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(cols, image_batch, label_batch):\n",
    "\n",
    "    rows = int(BATCH_SIZE / cols) \n",
    "    if rows * cols < BATCH_SIZE:\n",
    "        rows += 1\n",
    "    width = 3 * rows\n",
    "    height = 3 * cols\n",
    "    \n",
    "    \n",
    "    f, axes= plt.subplots(rows,cols,figsize=(height,width))\n",
    "    fig=plt.figure()\n",
    "    for n in range(BATCH_SIZE):\n",
    "        \n",
    "        subplot_title=(\"class \"+ classNames[label_batch[n]==1][0])\n",
    "        axes.ravel()[n].set_title(subplot_title)  \n",
    "        axes.ravel()[n].imshow(image_batch[n])\n",
    "        axes.ravel()[n].axis('off')\n",
    "\n",
    "    fig.tight_layout()    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def show_history(history):\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "def show_accuracies(): \n",
    "    fig, ax = plt.subplots()\n",
    "    X = np.arange(2)\n",
    "\n",
    "    models = ['bad val set', 'good val set']\n",
    "    plt.bar(X, [evalV1[1], evalV2[1]], width = 0.4, color = 'b', label='test')\n",
    "    plt.bar(X + 0.4, [valV1[1], valV2[1]], color = 'r', width = 0.4, label = \"val\")\n",
    "    plt.xticks(X + 0.4 / 2, models)\n",
    "    plt.ylim(top = 1.0, bottom = 0.80)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_misclassified(predictions, ground_truth, images, num_rows= 5, num_cols=3):\n",
    "    \n",
    "    # Plot the first X test images with wrong predictions.\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    i = 0\n",
    "    k = 0\n",
    "    while k < len(images) and i < num_images:\n",
    "        predicted_label = np.argmax(predictions[k])\n",
    "        gt = np.where(ground_truth[k])[0][0]\n",
    "        if predicted_label != gt:\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "            plot_image(k, predictions[k], gt, images)\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "            plot_value_array(k, predictions[k], ground_truth)\n",
    "            i += 1\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label, img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(classNames[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                classNames[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(8))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[np.where(true_label)[0][0]].set_color('blue')    \n",
    "\n",
    "def plot_predictions(predictions, ground_truth, images, num_rows= 5, num_cols=3 ):\n",
    "\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    for i in range(min(num_images,len(images))):\n",
    "        gt = np.where(ground_truth[i])[0][0]\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions[i], gt, images)\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(i, predictions[i], ground_truth)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = np.array(['00000','00001', '00002', '00003', '00004', '00005', '00006', '00007'])\n",
    "\n",
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [32,32])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
